"""
Wave 4.0 Integration Service - Query Analysis and Intelligent Routing

This service integrates all Wave 4.0 components to provide a unified interface
for advanced query analysis, intelligent routing, and performance monitoring.
"""

import asyncio
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple

from ..models.query_features import QueryFeatures
from ..models.routing_decision import RoutingDecision, RoutingConstraints
from ..services.query_analyzer import get_query_analyzer
from ..services.intelligent_query_router import get_intelligent_query_router
from ..services.query_preprocessor import get_query_preprocessor, PreprocessingConfig
from ..services.query_history_analyzer import get_query_history_analyzer
from ..services.routing_performance_tracker import get_routing_performance_tracker


logger = logging.getLogger(__name__)


class Wave4IntegrationService:
    """
    Unified service that integrates all Wave 4.0 components for comprehensive
    query analysis, intelligent routing, and performance optimization.
    """

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # Component instances (initialized lazily)
        self._query_analyzer = None
        self._intelligent_router = None
        self._query_preprocessor = None
        self._history_analyzer = None
        self._performance_tracker = None

        # Integration statistics
        self.integration_stats = {
            'total_queries_processed': 0,
            'average_end_to_end_time_ms': 0.0,
            'preprocessing_enabled': True,
            'performance_tracking_enabled': True,
            'history_learning_enabled': True,
            'component_health': {
                'query_analyzer': True,
                'intelligent_router': True,
                'query_preprocessor': True,
                'history_analyzer': True,
                'performance_tracker': True
            }
        }

        # Configuration
        self.config = {
            'enable_preprocessing': True,
            'enable_performance_tracking': True,
            'enable_history_learning': True,
            'enable_adaptive_routing': True,
            'max_processing_time_ms': 5000.0,
            'preprocessing_config': PreprocessingConfig(),
            'routing_constraints': RoutingConstraints()
        }

    async def _ensure_components_initialized(self):
        """Ensure all components are initialized."""
        if self._query_analyzer is None:
            self._query_analyzer = await get_query_analyzer()

        if self._intelligent_router is None:
            self._intelligent_router = await get_intelligent_query_router(self._query_analyzer)

        if self._query_preprocessor is None:
            self._query_preprocessor = get_query_preprocessor(self.config['preprocessing_config'])

        if self._history_analyzer is None:
            self._history_analyzer = get_query_history_analyzer()

        if self._performance_tracker is None:
            self._performance_tracker = get_routing_performance_tracker()

    async def process_query_complete(self, query: str,
                                   constraints: Optional[RoutingConstraints] = None,
                                   track_performance: bool = True) -> Dict[str, Any]:
        """
        Complete end-to-end query processing with all Wave 4.0 capabilities.

        Args:
            query: The raw query string
            constraints: Optional routing constraints
            track_performance: Whether to track performance metrics

        Returns:
            Complete processing results with routing decision and metadata
        """
        start_time = time.time()

        try:
            await self._ensure_components_initialized()

            self.logger.debug(f"Starting complete Wave 4.0 processing for query: '{query[:50]}...'")

            result = {
                'original_query': query,
                'processing_stages': {},
                'routing_decision': None,
                'performance_metadata': {},
                'recommendations': [],
                'errors': []
            }

            # Stage 1: Query Preprocessing (if enabled)
            preprocessed_query = query
            if self.config['enable_preprocessing']:
                preprocessing_result = await self._query_preprocessor.preprocess_query(query)
                preprocessed_query = preprocessing_result.get_best_query()

                result['processing_stages']['preprocessing'] = {
                    'enabled': True,
                    'operations_applied': preprocessing_result.operations_applied,\n                    'quality_improvement': preprocessing_result.confidence_improvement,\n                    'processing_time_ms': preprocessing_result.processing_time_ms,\n                    'issues_detected': preprocessing_result.issues_detected,\n                    'fixes_applied': preprocessing_result.fixes_applied\n                }\n                \n                self.logger.debug(f\"Preprocessing complete: {len(preprocessing_result.operations_applied)} operations\")\n            else:\n                result['processing_stages']['preprocessing'] = {'enabled': False}\n            \n            # Stage 2: Query Analysis\n            query_features = await self._query_analyzer.analyze_query(preprocessed_query)\n            \n            result['processing_stages']['analysis'] = {\n                'query_type': query_features.query_type.value,\n                'complexity': query_features.complexity.value,\n                'confidence_score': query_features.confidence_score,\n                'processing_time_ms': query_features.processing_time_ms,\n                'advanced_metrics': query_features.metadata.get('advanced_metrics', {})\n            }\n            \n            self.logger.debug(\n                f\"Query analysis complete: type={query_features.query_type.value}, \"\n                f\"complexity={query_features.complexity.value}\"\n            )\n            \n            # Stage 3: Historical Analysis and Learning (if enabled)\n            historical_recommendation = None\n            if self.config['enable_history_learning']:\n                try:\n                    historical_recommendation = self._history_analyzer.get_routing_recommendation(query_features)\n                    \n                    result['processing_stages']['historical_analysis'] = {\n                        'enabled': True,\n                        'recommendation': historical_recommendation,\n                        'has_historical_data': historical_recommendation['confidence'] > 0.5\n                    }\n                    \n                    self.logger.debug(f\"Historical analysis: {historical_recommendation['reasoning']}\")\n                except Exception as e:\n                    result['errors'].append(f\"Historical analysis error: {str(e)}\")\n                    result['processing_stages']['historical_analysis'] = {'enabled': True, 'error': str(e)}\n            else:\n                result['processing_stages']['historical_analysis'] = {'enabled': False}\n            \n            # Stage 4: Intelligent Routing\n            routing_constraints = constraints or self.config['routing_constraints']\n            \n            # Incorporate historical recommendations into constraints if available\n            if historical_recommendation and historical_recommendation['confidence'] > 0.7:\n                # Boost the historically successful mode\n                if hasattr(routing_constraints, 'mode_preferences'):\n                    routing_constraints.mode_preferences = {\n                        historical_recommendation['suggested_mode']: 1.2\n                    }\n            \n            routing_decision = await self._intelligent_router.route_query(query_features, routing_constraints)\n            \n            result['routing_decision'] = {\n                'selected_mode': routing_decision.selected_mode,\n                'selection_confidence': routing_decision.selection_confidence,\n                'selection_rationale': routing_decision.selection_rationale,\n                'performance_expectations': routing_decision.get_performance_summary(),\n                'alternatives': [\n                    {'mode': alt.mode, 'confidence': alt.confidence, 'pros': alt.pros, 'cons': alt.cons}\n                    for alt in routing_decision.alternatives[:3]  # Top 3 alternatives\n                ],\n                'config_adjustments': routing_decision.config_adjustments\n            }\n            \n            result['processing_stages']['routing'] = {\n                'decision_time_ms': 0.0,  # Would be measured in actual implementation\n                'alternatives_considered': len(routing_decision.alternatives),\n                'decision_complexity': routing_decision.decision_complexity,\n                'top_decision_factors': [\n                    {\n                        'name': factor.factor_name,\n                        'weight': factor.factor_weight,\n                        'value': factor.factor_value,\n                        'contribution': factor.get_weighted_contribution()\n                    }\n                    for factor in routing_decision.get_top_decision_factors(3)\n                ]\n            }\n            \n            self.logger.debug(\n                f\"Routing decision: {routing_decision.selected_mode} \"\n                f\"(confidence: {routing_decision.selection_confidence:.2f})\"\n            )\n            \n            # Stage 5: Generate Recommendations\n            recommendations = await self._generate_comprehensive_recommendations(\n                query_features, routing_decision, result\n            )\n            result['recommendations'] = recommendations\n            \n            # Stage 6: Performance Tracking Setup (if enabled)\n            if self.config['enable_performance_tracking'] and track_performance:\n                # Set up performance tracking for this query\n                # In a real implementation, this would return a tracking token\n                # that the caller would use to report actual results\n                \n                result['performance_tracking'] = {\n                    'enabled': True,\n                    'tracking_token': f\"{query_features.query_hash}_{int(time.time())}\",\n                    'expected_metrics': routing_decision.performance_metrics.__dict__,\n                    'monitoring_points': routing_decision.monitoring_metrics\n                }\n            else:\n                result['performance_tracking'] = {'enabled': False}\n            \n            # Calculate total processing time\n            total_time_ms = (time.time() - start_time) * 1000\n            \n            result['performance_metadata'] = {\n                'total_processing_time_ms': total_time_ms,\n                'stage_breakdown': {\n                    stage: data.get('processing_time_ms', 0) \n                    for stage, data in result['processing_stages'].items()\n                    if isinstance(data, dict) and 'processing_time_ms' in data\n                },\n                'overhead_ms': total_time_ms - sum(\n                    data.get('processing_time_ms', 0) \n                    for data in result['processing_stages'].values()\n                    if isinstance(data, dict)\n                ),\n                'processing_efficiency': self._calculate_processing_efficiency(result)\n            }\n            \n            # Update integration statistics\n            self._update_integration_stats(total_time_ms)\n            \n            self.logger.info(\n                f\"Wave 4.0 processing complete: {routing_decision.selected_mode} mode selected, \"\n                f\"total_time={total_time_ms:.2f}ms, \"\n                f\"confidence={routing_decision.selection_confidence:.2f}\"\n            )\n            \n            return result\n            \n        except Exception as e:\n            error_time_ms = (time.time() - start_time) * 1000\n            self.logger.error(f\"Error in Wave 4.0 processing: {e}\")\n            \n            return {\n                'original_query': query,\n                'error': str(e),\n                'processing_time_ms': error_time_ms,\n                'routing_decision': {\n                    'selected_mode': 'hybrid',  # Fallback\n                    'selection_confidence': 0.3,\n                    'selection_rationale': f'Fallback due to processing error: {str(e)}'\n                }\n            }\n    \n    async def report_query_performance(self, tracking_token: str, \n                                     actual_results: Dict[str, Any]) -> bool:\n        \"\"\"\n        Report actual performance results for a query.\n        \n        Args:\n            tracking_token: Token returned from process_query_complete\n            actual_results: Actual performance metrics\n            \n        Returns:\n            True if performance was successfully tracked\n        \"\"\"\n        try:\n            await self._ensure_components_initialized()\n            \n            # Extract query hash from tracking token\n            query_hash = tracking_token.split('_')[0]\n            \n            # Get the routing decision (would need to be stored/retrieved in real implementation)\n            # For now, we'll create a minimal decision\n            from ..models.routing_decision import RoutingDecision\n            routing_decision = RoutingDecision(\n                selected_mode=actual_results.get('mode_used', 'hybrid'),\n                selection_confidence=0.8,\n                selection_rationale=\"Performance tracking\"\n            )\n            \n            # Track the performance\n            performance_event = await self._performance_tracker.track_routing_performance(\n                query_hash, routing_decision, actual_results\n            )\n            \n            # Update history for learning\n            if self.config['enable_history_learning']:\n                # This would update the routing history\n                pass\n            \n            self.logger.debug(f\"Performance tracked for query {query_hash}: success={actual_results.get('success')}\")\n            \n            return True\n            \n        except Exception as e:\n            self.logger.error(f\"Error reporting query performance: {e}\")\n            return False\n    \n    async def _generate_comprehensive_recommendations(self, query_features: QueryFeatures,\n                                                   routing_decision: RoutingDecision,\n                                                   processing_result: Dict[str, Any]) -> List[str]:\n        \"\"\"Generate comprehensive recommendations based on analysis.\"\"\"\n        recommendations = []\n        \n        # Confidence-based recommendations\n        if routing_decision.selection_confidence < 0.6:\n            recommendations.append(\n                f\"Low routing confidence ({routing_decision.selection_confidence:.2f}) - \"\n                \"consider providing more specific query details\"\n            )\n        \n        # Complexity-based recommendations\n        if query_features.complexity.value == 'multi_faceted':\n            recommendations.append(\n                \"Complex query detected - consider breaking into simpler sub-queries for better results\"\n            )\n        \n        # Preprocessing recommendations\n        preprocessing_stage = processing_result['processing_stages'].get('preprocessing', {})\n        if preprocessing_stage.get('enabled') and len(preprocessing_stage.get('issues_detected', [])) > 0:\n            recommendations.append(\n                f\"Query issues detected during preprocessing - \"\n                f\"applied {len(preprocessing_stage.get('fixes_applied', []))} automatic fixes\"\n            )\n        \n        # Performance expectations\n        expected_latency = routing_decision.performance_metrics.expected_latency_ms\n        if expected_latency > 3000:\n            recommendations.append(\n                f\"Expected processing time is {expected_latency:.0f}ms - \"\n                \"consider simplifying query for faster results\"\n            )\n        \n        # Historical insights\n        historical_stage = processing_result['processing_stages'].get('historical_analysis', {})\n        if historical_stage.get('enabled') and not historical_stage.get('has_historical_data'):\n            recommendations.append(\n                \"No historical data available for this query pattern - \"\n                \"results may improve with usage\"\n            )\n        \n        # Mode-specific recommendations\n        mode_specific = {\n            'local': \"Focused search - may miss broader context\",\n            'global': \"Comprehensive search - may return many results\",\n            'hybrid': \"Balanced approach - good general purpose choice\",\n            'mix': \"Thorough analysis - highest accuracy but slower\"\n        }\n        \n        selected_mode = routing_decision.selected_mode\n        if selected_mode in mode_specific:\n            recommendations.append(f\"Using {selected_mode} mode: {mode_specific[selected_mode]}\")\n        \n        return recommendations\n    \n    def _calculate_processing_efficiency(self, result: Dict[str, Any]) -> float:\n        \"\"\"Calculate processing efficiency score.\"\"\"\n        total_time = result['performance_metadata']['total_processing_time_ms']\n        \n        # Base efficiency on time and quality\n        time_efficiency = max(0, min(1, (5000 - total_time) / 5000))  # 5s is considered slow\n        \n        # Quality factors\n        routing_confidence = result['routing_decision']['selection_confidence']\n        quality_score = routing_confidence\n        \n        # Preprocessing benefits\n        preprocessing = result['processing_stages'].get('preprocessing', {})\n        if preprocessing.get('enabled'):\n            quality_boost = preprocessing.get('quality_improvement', 0)\n            quality_score += quality_boost\n        \n        # Overall efficiency\n        efficiency = (time_efficiency * 0.4 + min(quality_score, 1.0) * 0.6)\n        return min(max(efficiency, 0.0), 1.0)\n    \n    def _update_integration_stats(self, processing_time_ms: float) -> None:\n        \"\"\"Update integration statistics.\"\"\"\n        self.integration_stats['total_queries_processed'] += 1\n        \n        # Update average processing time\n        total = self.integration_stats['total_queries_processed']\n        current_avg = self.integration_stats['average_end_to_end_time_ms']\n        new_avg = ((current_avg * (total - 1)) + processing_time_ms) / total\n        self.integration_stats['average_end_to_end_time_ms'] = new_avg\n    \n    async def get_system_health(self) -> Dict[str, Any]:\n        \"\"\"Get comprehensive system health information.\"\"\"\n        try:\n            await self._ensure_components_initialized()\n            \n            health_info = {\n                'overall_status': 'healthy',\n                'component_status': {},\n                'performance_metrics': {},\n                'recommendations': [],\n                'last_updated': datetime.now().isoformat()\n            }\n            \n            # Check component health\n            components = {\n                'query_analyzer': self._query_analyzer,\n                'intelligent_router': self._intelligent_router,\n                'query_preprocessor': self._query_preprocessor,\n                'history_analyzer': self._history_analyzer,\n                'performance_tracker': self._performance_tracker\n            }\n            \n            for name, component in components.items():\n                try:\n                    if hasattr(component, 'get_analysis_stats'):\n                        stats = component.get_analysis_stats()\n                        health_info['component_status'][name] = {\n                            'status': 'healthy',\n                            'stats': stats\n                        }\n                    elif hasattr(component, 'get_tracking_statistics'):\n                        stats = component.get_tracking_statistics()\n                        health_info['component_status'][name] = {\n                            'status': 'healthy',\n                            'stats': stats\n                        }\n                    else:\n                        health_info['component_status'][name] = {'status': 'healthy'}\n                except Exception as e:\n                    health_info['component_status'][name] = {\n                        'status': 'error',\n                        'error': str(e)\n                    }\n                    health_info['overall_status'] = 'degraded'\n            \n            # Get performance metrics\n            try:\n                dashboard = self._performance_tracker.get_performance_dashboard()\n                health_info['performance_metrics'] = {\n                    'overall_health_score': dashboard.overall_health_score,\n                    'active_alerts': dashboard.active_alerts_count,\n                    'total_queries_processed': dashboard.total_queries_processed,\n                    'average_response_time_ms': dashboard.average_response_time_ms,\n                    'realtime_metrics': dashboard.realtime_metrics\n                }\n                \n                # Add performance-based recommendations\n                health_info['recommendations'].extend(dashboard.recommendations)\n                \n                if dashboard.overall_health_score < 0.7:\n                    health_info['overall_status'] = 'degraded'\n                elif dashboard.overall_health_score < 0.5:\n                    health_info['overall_status'] = 'unhealthy'\n                    \n            except Exception as e:\n                health_info['performance_metrics'] = {'error': str(e)}\n            \n            # Integration-specific metrics\n            health_info['integration_metrics'] = self.integration_stats.copy()\n            \n            return health_info\n            \n        except Exception as e:\n            return {\n                'overall_status': 'error',\n                'error': str(e),\n                'last_updated': datetime.now().isoformat()\n            }\n    \n    async def analyze_historical_patterns(self, days: int = 30) -> Dict[str, Any]:\n        \"\"\"Analyze historical patterns for insights.\"\"\"\n        try:\n            await self._ensure_components_initialized()\n            \n            insights = await self._history_analyzer.analyze_query_history(days)\n            \n            return {\n                'analysis_period_days': days,\n                'total_queries_analyzed': insights.total_queries_analyzed,\n                'overall_success_rate': insights.overall_success_rate,\n                'trend_direction': insights.trend_direction,\n                'discovered_patterns': [\n                    {\n                        'pattern_id': pattern.pattern_id,\n                        'type': pattern.pattern_type,\n                        'description': pattern.pattern_description,\n                        'frequency': pattern.frequency,\n                        'strength': pattern.pattern_strength\n                    }\n                    for pattern in insights.discovered_patterns[:10]  # Top 10\n                ],\n                'mode_performance': insights.mode_performance,\n                'routing_effectiveness': insights.routing_effectiveness,\n                'recommendations': insights.routing_recommendations,\n                'analysis_confidence': insights.analysis_confidence\n            }\n            \n        except Exception as e:\n            return {\n                'error': str(e),\n                'analysis_period_days': days\n            }\n    \n    def update_configuration(self, config_updates: Dict[str, Any]) -> bool:\n        \"\"\"Update system configuration.\"\"\"\n        try:\n            for key, value in config_updates.items():\n                if key in self.config:\n                    self.config[key] = value\n                    self.logger.info(f\"Updated configuration: {key} = {value}\")\n            \n            # Update component configurations if needed\n            if 'preprocessing_config' in config_updates:\n                if self._query_preprocessor:\n                    self._query_preprocessor.update_configuration(config_updates['preprocessing_config'])\n            \n            return True\n            \n        except Exception as e:\n            self.logger.error(f\"Error updating configuration: {e}\")\n            return False\n    \n    def get_integration_statistics(self) -> Dict[str, Any]:\n        \"\"\"Get integration service statistics.\"\"\"\n        return {\n            **self.integration_stats,\n            'configuration': {\n                'preprocessing_enabled': self.config['enable_preprocessing'],\n                'performance_tracking_enabled': self.config['enable_performance_tracking'],\n                'history_learning_enabled': self.config['enable_history_learning'],\n                'adaptive_routing_enabled': self.config['enable_adaptive_routing']\n            },\n            'system_uptime': 'N/A',  # Would track in real implementation\n            'last_updated': datetime.now().isoformat()\n        }\n\n\n# Factory function\n_wave4_service_instance = None\n\n\nasync def get_wave4_integration_service() -> Wave4IntegrationService:\n    \"\"\"Get or create a Wave4IntegrationService instance.\"\"\"\n    global _wave4_service_instance\n    if _wave4_service_instance is None:\n        _wave4_service_instance = Wave4IntegrationService()\n    return _wave4_service_instance
